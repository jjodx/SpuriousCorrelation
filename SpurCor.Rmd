---
title: "Simulating for understanding p-values"
author: "Jean-Jacques Orban de Xivry"
date: "April 8, 2019"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(Hmisc) # for rcorr
library(MASS) # for mvnorm
library(ggplot2)
```

## To do for JJ

1) Make terminology clearer: population-variable-sample-observations
2) Use actual variables that we know are not correlated: height and QI? and some that are correlated with R=0.5: height and weight (even though this is not perfect)
3) make choise between simulation tutorial and statistis tutorial


## Introduction

## simulating a single correlation R=0

```{r, echo=FALSE}
set.seed(12)# to make sure everybody gets the same results
PopSize=15
x=mvrnorm(PopSize,0,1,empirical = FALSE)
y=mvrnorm(PopSize,0,1,empirical = FALSE)
R<-rcorr(x,y)
Scatter1 <- data.frame(x,y)
PP4 <- ggplot(Scatter1, aes(x=x, y=y)) +
  geom_point()+
  geom_smooth(method='lm',formula=y~x)+
  labs(title = "",x="Random variable 1", y="Random variable 2")
```

In the first step of this tutorial, we will build two variables x and y that are compmletely random (Gaussian distribution with mean=0 and standard deviation = 1). Each variable will be sampled `r PopSize` times. Each sampled element of x (xi) with an element of y (yi) to have pairs of (xi,yi). Then, we will compute the correlation between x and y.
Off course, one should not expect any correlation between x and y as these are sampled from random distribution.
One can achieve that in R by using the `mvrnorm` function from the MASS package. To draw `r PopSize` samples from a normal distribution, we can have `x=mvrnorm(``r PopSize` `,0,1,empirical = FALSE)` and `y=mvrnorm(` `r PopSize` `,0,1,empirical = FALSE)`

Together, these two variables are uncorrelated with a correlation coefficient R= `r format(R$r[1,2], digits = 3)` (p-value = `r format(R$P[1,2], digits = 3)`). This is expected as we sampled two random variables. Therefore, the correlation between these two samples should be non-significant as there is not link between them.
````{r, echo=FALSE} 
PP4
```

## What is the expected p-value distribution if there are no correlations
``` {r, echo=FALSE}
set.seed(123)# to make sure everybody gets the same results
Rval = 0 # value of the simulated correlation
Nsim=1000
  res <- data.frame(p=rep(NA,Nsim),R=rep(NA,Nsim),Sig=rep(NA,Nsim))
Sigma <- matrix(c(1,Rval,Rval,1),2,2)
for (i in c(1:Nsim)){
      D <- mvrnorm(n = PopSize, rep(0, 2), Sigma, empirical = FALSE)
      R<-rcorr(D[,1],D[,2])
      res[i,"R"] <- R$r[1,2]
      res[i,"p"]<-R$P[1,2]
      res[i,"Sig"]<-res[i,"p"]<0.05
}

Fcolor <- c("orange","lightblue")
CountSig <- sum(res$Sig)
Psig <- CountSig/length(res$Sig)
res$Sig = factor(1-res$Sig)
PP2 <- ggplot(res, aes(x=p, fill=Sig)) + 
    geom_histogram(aes(x=p,fill=Sig),binwidth=.05,boundary = 0.05,color="black") +
    scale_fill_manual(values = Fcolor) +
    geom_hline(yintercept=CountSig, linetype="dashed", color = "black") +
    geom_label(aes(x = 0, y = CountSig, label = "H0"), 
               hjust = "left", 
               vjust = "bottom", 
               colour = "black", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    coord_cartesian(xlim = c(0, 1))+
    theme(legend.position='none')+
    scale_y_continuous(expand = c(0.1,0)) +
    labs(title="",x="p-value" , y="Count")
```

Simulating such correlation repeatedly can allow one to look at the distribution of p-values when no correlations are present.
When there is no correlation between two variables as it is the case here, one should expect a flat distribuation of p-values with 5% of the p-values being below the 5% typical significance threshold. We will simulate such correlation 10000 times in order to obtain a reliable distribution of the p-values. In each iteration of the algorithm, we will simultaneously draw `r PopSize` samples from two uncorrelated variables. The covariance matrix between these two uncorrelated variables should be `Sigma <- matrix(c(1,0,0,1),2,2)`, which gives:
$$
Sigma = \begin{pmatrix}
1 & 0\\
0 & 1
\end{pmatrix}
$$
Using this covariance matrix, we will use the `mvnorm` function to build two uncorrelated variables at the same time:
`D=mvnorm(` `r PopSize` `,rep(0, 2),Sigma)`, where the first column of D corresponds to the x random variables and the second to the y random variable. We will correlate these two random variables together and store the p-value for each stimulated pair of x,y variables (`r PopSize` samples for each stimulation). This is repeated a number of times (`Nsim=` `r Nsim`)

``` {r eval=FALSE}
Nsim=1000 # number of simulations
PopSize = 15 #number os elements in each sample
res <- data.frame(p=rep(NA,Nsim),R=rep(NA,Nsim),Sig=rep(NA,Nsim)) # pre-allocating space for the dataframe
for (i in c(1:Nsim)){
  # drawing 10 elements for each random variable (x and y) with a covariance matrix equal to Sigma
  D <- mvrnorm(n = PopSize, rep(0, 2), Sigma, empirical = FALSE) 
  R<-rcorr(D[,1],D[,2]) # correlation between the x and y variables
  res[i,"R"] <- R$r[1,2] # storing the correlation value for further use
  res[i,"p"]<-R$P[1,2]# storing the p-value for further use
  res[i,"Sig"]<-res[i,"p"]<0.05 # tag p-values smaller than the type II error threshold (here 0.05)
}
```

In the code above the R-dataframe `res` stores the results of the correlation between x (first colunm of D - `D[,1]`) and y (second column of D = `D[,2]`). The value of the correlation coefficient (`R$r[1,2]`) and the associated p-value (`R$p[1,2]`) are stored in this dataframe.

In the absence of correlation, one should expect a uniform distribution of the p-values from 0 to 1. This is what is obseved in the graph below:
``` {r eval=FALSE}
# plotting the distribution of p-values
Fcolor <- c("orange","lightblue")
ggplot(res, aes(x=p, fill=Sig)) + 
  geom_histogram(aes(x=p,fill=Sig),binwidth=.05,boundary = 0.05,color="black")+
  scale_fill_manual(values = Fcolor)
```

```{r, echo=FALSE} 
PP2
```

Interestingly, even in the absence of correlation between x and y, there is a subset of correlations associated with a p-value under the type II error threshold. Those are highlighted in orange in the figure above and are called false-positives. That is, these correlations are significant despite the fact that the variables x and y (from which only a few sample was taken) are not correlated by design. Given that the distribution of p-values is uniform and p-values fall in the interval [0,1], there will always be 5% of the p-values under the threshold of 0.05, independently of the number of samples for the two variables (one can test that by increasing the value of PopSize in the code above and re-running the code).

### understanding the influence of sample size (and power) on the magnitude of the false-positive correlations

``` {r, echo=FALSE}
  Rsig <- mean(res$R[res$Sig==0])
  Rall <- mean(res$R)
  if (Rsig>Rval){Rpos <- c("left","right")}else{Rpos <- c("right","left")}
PP1 <- ggplot(res, aes(x=R, fill=Sig)) + 
    geom_histogram(aes(x=R,fill=Sig),binwidth=.05,boundary = 0,color="black") +
    scale_fill_manual(values = Fcolor) +
    coord_cartesian(xlim = c(-1, 1))+
    geom_vline(xintercept=Rsig, linetype="dashed", color = "darkorange", size = 1) +
    geom_label(aes(x = Rsig, y = Inf, label = "Sig."), 
               hjust = Rpos[1], 
               vjust = "top", 
               colour = "darkorange", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    geom_vline(xintercept=Rval, linetype="dashed", color = "darkblue", size = 1) +
    geom_label(aes(x = Rval, y=Inf, label = "Actual"),
               hjust = Rpos[2], 
               vjust = "top", 
               colour = "darkblue", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    theme(legend.position='none') +
    scale_y_continuous(expand = c(0.15,0)) +
    labs(title="",x="correlation coefficient" , y="Count")
```
The distribution of the correlation coefficient will allow us to understand the problem with small sample size and why significant results always look convincing with small sample size.
To plot the distribution of simulated correlation coefficient, one can use the `res` dataframe:
```{r, eval=FALSE} 
ggplot(res, aes(x=R, fill=Sig)) + 
    geom_histogram(aes(x=R,fill=Sig),binwidth=.05,boundary = 0,color="black") +
    scale_fill_manual(values = Fcolor)
```

The false-positive correlations are associated with rather large correlations (absolute value > 0.6). 

```{r, echo=FALSE} 
PP1
```

That is, when using small sample size (here 10 observations for each variable), false-positive correlations have a high value and appear therefore very convincing. "Such a large correlation can only be true" would say an inexperienced scientist. Such high false-positive correlation is often accepted as solid proof but his part of the significance fallacy.

``` {r echo=FALSE}
PopSize75 = 75 #number os elements in each sample
res75 <- data.frame(p=rep(NA,Nsim),R=rep(NA,Nsim),Sig=rep(NA,Nsim)) # pre-allocating space for the dataframe
for (i in c(1:Nsim)){
  # drawing 75 elements for each random variable (x and y) with a covariance matrix equal to Sigma
  D <- mvrnorm(n = PopSize75, rep(0, 2), Sigma, empirical = FALSE) 
  R<-rcorr(D[,1],D[,2]) # correlation between the x and y variables
  res75[i,"R"] <- R$r[1,2] # storing the correlation value for further use
  res75[i,"p"]<-R$P[1,2]# storing the p-value for further use
  res75[i,"Sig"]<-res75[i,"p"]<0.05 # tag p-values smaller than the type II error threshold (here 0.05)
}
CountSig75 <- sum(res75$Sig)
Psig75 <- CountSig75/length(res75$Sig)
res75$Sig = factor(1-res75$Sig)
Rsig <- mean(res75$R[res75$Sig==0])
Rall <- mean(res75$R)
if (Rsig>Rval){Rpos <- c("left","right")}else{Rpos <- c("right","left")}
PP175 <- ggplot(res75, aes(x=R, fill=Sig)) + 
  geom_histogram(aes(x=R,fill=Sig),binwidth=.05,boundary = 0,color="black") +
  scale_fill_manual(values = Fcolor) +
  coord_cartesian(xlim = c(-1, 1))+
  geom_vline(xintercept=Rsig, linetype="dashed", color = "darkorange", size = 1) +
  geom_label(aes(x = Rsig, y = Inf, label = "Sig."), 
             hjust = Rpos[1], 
             vjust = "top", 
             colour = "darkorange", 
             label.size = NA, 
             size = 3,
             fill = NA)+
  geom_vline(xintercept=Rval, linetype="dashed", color = "darkblue", size = 1) +
  geom_label(aes(x = Rval, y=Inf, label = "Actual"),
             hjust = Rpos[2], 
             vjust = "top", 
             colour = "darkblue", 
             label.size = NA, 
             size = 3,
             fill = NA)+
  theme(legend.position='none') +
  scale_y_continuous(expand = c(0.15,0)) +
  labs(title="",x="correlation coefficient" , y="Count")

PP175
```

Increasing the sample size has a direct influence on the magnitude of these false-positive correlations. One can build a new `res` dataframe with the sample size of `r PopSize75` (`PopSize =` `r PopSize75`).

The significance fallacy has important consequences for the publishability of findings. If two researchers are (unknowingly) reporting a false-positive correlation with N=`r PopSize` and R=0.7 for researcher A and with N=`r PopSize75` and R=0.4 for researcher B, which one will more easily publish in a high-impact journal (whatever that means...)?

### understanding the multiple comparison problem.

these simulations also show that if we keep simulating random variables, we are assured of getting at least one significant correlation. With `r Nsim` simulations, there is 100% chance that at least one correlation will be significant. This exemplifies that if someone keeps trying to test correlation between many possible variables, the probability of getting a significant correlation even if there should be no correlation.

```{r, echo=FALSE}
Rval50 = 0.5
```

## simulating a single correlation R=`r Rval50`

To simulate two variables with a given correlation, one can also use the `mvnorm` function but this time with a covariance matrix exhibiting the value for the simulated correlation on the off-diagonal elements. For instance, if we want to simulate two variables with a correlation of R=`r Rval50`, then the covariance matrix is:
$$
Sigma = \begin{pmatrix}
1 & `r Rval50`\\
`r Rval50` & 1
\end{pmatrix}
$$
```{r, echo=FALSE}
set.seed(12)# to make sure everybody gets the same results
Sigma <- matrix(c(1,Rval50,Rval50,1),2,2)
D <- mvrnorm(n = PopSize, rep(0, 2), Sigma, empirical = FALSE) 
  R<-rcorr(D[,1],D[,2]) # correlation between the x and y variables
Scatter2 <- data.frame(x=D[,1],y=D[,2])
PP4 <- ggplot(Scatter2, aes(x=x, y=y)) +
  geom_point()+
  geom_smooth(method='lm',formula=y~x)+
  labs(title = "",x="Random variable 1", y="Random variable 2")

PP4
```
Together, these two variables are correlated with a correlation coefficient R= `r format(R$r[1,2], digits = 3)` (p-value = `r format(R$P[1,2], digits=3)`). Off course, the correlation between these two variables is not exactly zero. We will see later how we can recover the actual simulated correlation. 

Now, we will repeat this process a number of times in order to obtain the distribution of the p-values when there is a correlation R=`r Rval50`. 
When there is an underlying correlation between the two variables, the distribution of p-values becomes asymmetric with more p-values under 0.05.
``` {r, echo=FALSE}
set.seed(123)# to make sure everybody gets the same results
res <- data.frame(p=rep(NA,Nsim),R=rep(NA,Nsim),Sig=rep(NA,Nsim))
Sigma <- matrix(c(1,Rval50,Rval50,1),2,2)
for (i in c(1:Nsim)){
      D <- mvrnorm(n = PopSize, rep(0, 2), Sigma, empirical = FALSE)
      R<-rcorr(D[,1],D[,2])
      res[i,"R"] <- R$r[1,2]
      res[i,"p"]<-R$P[1,2]
      res[i,"Sig"]<-res[i,"p"]<0.05
}

Fcolor <- c("orange","lightblue")
CountSig <- sum(res$Sig)
Psig <- CountSig/length(res$Sig)
res$Sig = factor(1-res$Sig)
PP2 <- ggplot(res, aes(x=p, fill=Sig)) + 
    geom_histogram(aes(x=p,fill=Sig),binwidth=.05,boundary = 0.05,color="black") +
    scale_fill_manual(values = Fcolor) +
    geom_hline(yintercept=CountSig, linetype="dashed", color = "black") +
    geom_label(aes(x = 0, y = CountSig, label = "H0"), 
               hjust = "left", 
               vjust = "bottom", 
               colour = "black", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    coord_cartesian(xlim = c(0, 1))+
    theme(legend.position='none')+
    scale_y_continuous(expand = c(0.1,0)) +
    labs(title="",x="p-value" , y="Count")

PP2

d=data.frame(x1=c(0.33,0.33), x2=c(0.66,0.66), y1=c(0,Psig), y2=c(Psig,1), t=c('a','b'))
  PP3 <- ggplot() +  
    geom_rect(data=d, mapping=aes(xmin=x1, xmax=x2, ymin=y1, ymax=y2, fill=t), 
              color="black") +
    scale_fill_manual(values = Fcolor, 
                      name="",
                      labels=c("p<=0.05", "p>0.05")) +
    geom_hline(yintercept=0.05, linetype="dashed", color = "red") +
    geom_label(aes(x = 0.1, y = 0.05, label = "Type 1 \nError"), 
               hjust = "center", 
               vjust = "bottom", 
               colour = "red", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    geom_hline(yintercept=0.8, linetype="dashed", color = "black") +
    geom_label(aes(x = 0.1, y = 0.8, label = "Type 2 \nError"), 
               hjust = "center", 
               vjust = "center", 
               colour = "black", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    geom_hline(yintercept=0, color = "black") +
    coord_cartesian(xlim = c(0, 1),ylim = c(0, 1))+
    labs(title="",y="\n \n \nProportion of simulations")+
    scale_y_continuous(expand = c(0,0)) +
    theme(axis.text.x=element_blank(),
          axis.ticks.x=element_blank())
```

### understanding power

However, note that not all simulated correlations are significant. The percentage of significant correlations is equal the power of an experiment designed to detect a correlation of R=`r Rval` with `r PopSize` observations. Indeed, the power of an experiment can be defined as the chance that an experiment designed to detect a given effect (here a correlation) will actually do so (100%-power is also referred to as type II error or false negative). In our case, we performed as many experiments as we simulated correlations but only `r format(100*Psig, digits = 1)`% from them were significant. That means that if we have `r PopSize` observations from two populations that are correlated with R=`r Rval`, we have `r format(100*Psig, digits = 1)`% of detecting a significant correlation. This is illustrated on the graph below:

``` {r echo=FALSE}
PP3
PopSize28 = 28
set.seed(123)# to make sure everybody gets the same results
Nsim=1000
  res28 <- data.frame(p=rep(NA,Nsim),R=rep(NA,Nsim),Sig=rep(NA,Nsim))
Sigma <- matrix(c(1,Rval50,Rval50,1),2,2)
for (i in c(1:Nsim)){
      D <- mvrnorm(n = PopSize28, rep(0, 2), Sigma, empirical = FALSE)
      R<-rcorr(D[,1],D[,2])
      res28[i,"R"] <- R$r[1,2]
      res28[i,"p"]<-R$P[1,2]
      res28[i,"Sig"]<-res28[i,"p"]<0.05
}

Fcolor <- c("orange","lightblue")
CountSig28 <- sum(res28$Sig)
Psig28 <- CountSig28/length(res28$Sig)
res28$Sig = factor(1-res28$Sig)
d=data.frame(x1=c(0.33,0.33), x2=c(0.66,0.66), y1=c(0,Psig28), y2=c(Psig28,1), t=c('a','b'))
  PP28 <- ggplot() +  
    geom_rect(data=d, mapping=aes(xmin=x1, xmax=x2, ymin=y1, ymax=y2, fill=t), 
              color="black") +
    scale_fill_manual(values = Fcolor, 
                      name="",
                      labels=c("p<=0.05", "p>0.05")) +
    geom_hline(yintercept=0.05, linetype="dashed", color = "red") +
    geom_label(aes(x = 0.1, y = 0.05, label = "Type 1 \nError"), 
               hjust = "center", 
               vjust = "bottom", 
               colour = "red", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    geom_hline(yintercept=0.8, linetype="dashed", color = "black") +
    geom_label(aes(x = 0.1, y = 0.8, label = "Type 2 \nError"), 
               hjust = "center", 
               vjust = "center", 
               colour = "black", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    geom_hline(yintercept=0, color = "black") +
    coord_cartesian(xlim = c(0, 1),ylim = c(0, 1))+
    labs(title="",y="\n \n \nProportion of simulations")+
    scale_y_continuous(expand = c(0,0)) +
    theme(axis.text.x=element_blank(),
          axis.ticks.x=element_blank())
```

As indicated on this graph, the expected power of an experiment is 80% (or 90%). Yet, this is here not the case. To detect a correlation R=`r Rval`, one needs `r PopSize28` observations. In this case, the percentage of significant correlations reaches the power requirement of 80%.
``` {r echo=FALSE}
PP28
```

This manipulations demonstrate how one can get insights about the required sample size for detecting a correlation of a given value, do some simulations.
### effect of sample size on the accuracy of correlation estimation.

``` {r, echo=FALSE}
  Rsig <- mean(res$R[res$Sig==0])
  Rall <- mean(res$R)
  if (Rsig>Rval50){Rpos <- c("left","right")}else{Rpos <- c("right","left")}
PP150 <- ggplot(res, aes(x=R, fill=Sig)) + 
    geom_histogram(aes(x=R,fill=Sig),binwidth=.05,boundary = 0,color="black") +
    scale_fill_manual(values = Fcolor) +
    coord_cartesian(xlim = c(-1, 1))+
    geom_vline(xintercept=Rsig, linetype="dashed", color = "darkorange", size = 1) +
    geom_label(aes(x = Rsig, y = Inf, label = "Sig."), 
               hjust = Rpos[1], 
               vjust = "top", 
               colour = "darkorange", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    geom_vline(xintercept=Rval50, linetype="dashed", color = "darkblue", size = 1) +
    geom_label(aes(x = Rval50, y=Inf, label = "Actual"),
               hjust = Rpos[2], 
               vjust = "top", 
               colour = "darkblue", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    theme(legend.position='none') +
    scale_y_continuous(expand = c(0.15,0)) +
    labs(title="",x="correlation coefficient" , y="Count")
PP150
```

``` {r, echo=FALSE}
  Rsig <- mean(res28$R[res28$Sig==0])
  Rall <- mean(res28$R)
  if (Rsig>Rval50){Rpos <- c("left","right")}else{Rpos <- c("right","left")}
PP150_28 <- ggplot(res28, aes(x=R, fill=Sig)) + 
    geom_histogram(aes(x=R,fill=Sig),binwidth=.05,boundary = 0,color="black") +
    scale_fill_manual(values = Fcolor) +
    coord_cartesian(xlim = c(-1, 1))+
    geom_vline(xintercept=Rsig, linetype="dashed", color = "darkorange", size = 1) +
    geom_label(aes(x = Rsig, y = Inf, label = "Sig."), 
               hjust = Rpos[1], 
               vjust = "top", 
               colour = "darkorange", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    geom_vline(xintercept=Rval50, linetype="dashed", color = "darkblue", size = 1) +
    geom_label(aes(x = Rval50, y=Inf, label = "Actual"),
               hjust = Rpos[2], 
               vjust = "top", 
               colour = "darkblue", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    theme(legend.position='none') +
    scale_y_continuous(expand = c(0.15,0)) +
    labs(title="",x="correlation coefficient" , y="Count")
```

On the graph above, we can see that while many simulated correlations are around the value of `r Rval50`. However, the simulated correlations span a large range between `r format(min(res$R),digits==2)` and  `r format(max(res$R),digits==2)`. One can look at the effect of sample size on the precision of the estimated correlation. It is obvious that increasing the sample size (N= `r PopSize28`) decreases the range of simulated correlation ([`r format(min(res28$R),digits==2)`,`r format(max(res28$R),digits==2)`]). This has been described previously and illustrates that high power (here 80%) does not always correspond to high precision given the remaining variability of the simulated correlations.

``` {r echo=FALSE}
PP150_28
```

### understanding that publication bias inflates effect size

If we look at the mean correlation from only significant studies, it is always larger than the actual population average correlation.

## What is the expected p-value distribution if there is a correlation

## simulating multiple correlations, bootstrap

## How sensisitive are correlations to one outlier?

## Solution to the outlier problem
### robust parametric correlation
### non-parametric correlation - Spearman

## How sensisitive are correlations to subgroups?

## Solution to the subgroup problem
### Spearmann is not a solution
### Taking subgroups into account

## The multiple comparison problem

## extending this line of thought to the T-test
