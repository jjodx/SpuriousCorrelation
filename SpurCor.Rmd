---
title: "Simulating for understanding p-values"
author: "Jean-Jacques Orban de Xivry"
date: "April 8, 2019"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(Hmisc) # for rcorr
library(MASS) # for mvnorm
library(ggplot2)
```

## To do for JJ

1) Make terminology clearer: population-variable-sample-observations
2) Use actual variables that we know are not correlated: height and QI? and some that are correlated with R=0.5: height and weight (even though this is not perfect)
3) make choise between simulation tutorial and statistis tutorial
4) compute CI instead of range for precision of correlations
5) link with ShinyApp

Refer to Bishop blog:
http://deevybee.blogspot.com/2017/11/how-analysis-of-variance-works.html
https://deevybee.blogspot.com/2017/11/anova-t-tests-and-regression-different.html
https://deevybee.blogspot.com/2017/12/using-simulations-to-understand.html
http://deevybee.blogspot.com/2017/12/using-simulations-to-understand-p-values.html
https://www.slideshare.net/deevybishop/introduction-to-simulating-data-to-improve-your-research

# Introduction

# Learning about statistics from simulated correlations.

```{r, echo=FALSE}
PopSize=15
Nsim=100 # should be 1000
```

Let's imagine the following experiment. Researchers in Syldavia are willing to measure height and working memory capacity in a population of young healthy participants because they think that these two parameters are correlated with each other. Because of their limited budget, they are able to measure these parameters in a population of `r PopSize`  participants. For each individual participant `i`, they have two observations: `(x~i~,y~i~)` where `x~i~` is the height of the participant and `y~i~` is his/her working memory capacity.
To simulate this experiment numerically, we can generate `r PopSize` random numbers with mean of 0 and standard deviation of 1 corresponding to the simulated height of each participant and `r PopSize` different random numbers with mean of 0 and standard deviation of 1 corresponding to the simulated working memory capacity of each participant. A mean of 0 and a standard deviation of 1 were chosen for simplicity but all the arguments below hold if ones picks another mean and/or another standard deviation. By doing this, we have generated `r PopSize` pairs of height and working memory capacity. To follow the idea of our Syldavian researchers, we can then compute the correlation between height and working memory capacity of our randomly generated population.

## simulating a single correlation R=0

```{r, echo=FALSE}
set.seed(12)# to make sure everybody gets the same results
x=mvrnorm(PopSize,0,1,empirical = FALSE)
y=mvrnorm(PopSize,0,1,empirical = FALSE)
R<-rcorr(x,y)
Scatter1 <- data.frame(x,y)
PP4 <- ggplot(Scatter1, aes(x=x, y=y)) +
  geom_point()+
  geom_smooth(method='lm',se=FALSE)+
  labs(title = "",x="Random variable 1", y="Random variable 2")
```

In the first step of this tutorial, we will use `R` to build two variables x and y that are compmletely random (Gaussian distribution with mean=0 and standard deviation = 1). Each variable will be measured `r PopSize` times. Each sampled element of x (xi) with an element of y (yi) to have pairs of (xi,yi). Then, we will compute the correlation between x and y.

Off course, one should not expect any correlation between x and y as these are sampled from random distribution.
One can achieve that in R by using the `mvrnorm` function from the MASS package. To draw `r PopSize` samples from a normal distribution, we can have `x=mvrnorm(``r PopSize` `,0,1,empirical = FALSE)` and `y=mvrnorm(` `r PopSize` `,0,1,empirical = FALSE)`

Together, these two variables are uncorrelated with a correlation coefficient R= `r format(R$r[1,2], digits = 3)` (p-value = `r format(R$P[1,2], digits = 3)`). This is expected as we sampled two random variables. Therefore, the correlation between these two samples should be non-significant as there is not link between them.
````{r, echo=FALSE} 
PP4
```

## What is the expected p-value distribution if there are no correlations
``` {r, echo=FALSE}
set.seed(123)# to make sure everybody gets the same results
Rval = 0 # value of the simulated correlation
  res <- data.frame(p=rep(NA,Nsim),R=rep(NA,Nsim),Sig=rep(NA,Nsim))
Sigma <- matrix(c(1,Rval,Rval,1),2,2)
for (i in c(1:Nsim)){
      D <- mvrnorm(n = PopSize, rep(0, 2), Sigma, empirical = FALSE)
      R<-rcorr(D[,1],D[,2])
      res[i,"R"] <- R$r[1,2]
      res[i,"p"]<-R$P[1,2]
      res[i,"Sig"]<-res[i,"p"]<0.05
}

Fcolor <- c("orange","lightblue")
CountSig <- sum(res$Sig)
Psig <- CountSig/length(res$Sig)
res$Sig = factor(1-res$Sig)
PP2 <- ggplot(res, aes(x=p, fill=Sig)) + 
    geom_histogram(aes(x=p,fill=Sig),binwidth=.05,boundary = 0.05,color="black") +
    scale_fill_manual(values = Fcolor) +
    geom_hline(yintercept=CountSig, linetype="dashed", color = "black") +
    geom_label(aes(x = 0, y = CountSig, label = "H0"), 
               hjust = "left", 
               vjust = "bottom", 
               colour = "black", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    coord_cartesian(xlim = c(0, 1))+
    theme(legend.position='none')+
    scale_y_continuous(expand = c(0.1,0)) +
    labs(title="",x="p-value" , y="Count")
```

Simulating such correlation repeatedly can allow one to look at the distribution of p-values when no correlations are present.
When there is no correlation between two variables as it is the case here, one should expect a flat distribuation of p-values with 5% of the p-values being below the 5% typical significance threshold. We will simulate such correlation 10000 times in order to obtain a reliable distribution of the p-values. In each iteration of the algorithm, we will simultaneously draw `r PopSize` samples from two uncorrelated variables. The covariance matrix between these two uncorrelated variables should be `Sigma <- matrix(c(1,0,0,1),2,2)`, which gives:
$$
Sigma = \begin{pmatrix}
1 & 0\\
0 & 1
\end{pmatrix}
$$
Using this covariance matrix, we will use the `mvnorm` function to build two uncorrelated variables at the same time:
`D=mvnorm(` `r PopSize` `,rep(0, 2),Sigma)`, where the first column of D corresponds to the x random variables and the second to the y random variable. We will correlate these two random variables together and store the p-value for each stimulated pair of x,y variables (`r PopSize` samples for each stimulation). This is repeated a number of times (`Nsim=` `r Nsim`)

``` {r eval=FALSE}
Nsim=1000 # number of simulations
PopSize = 15 #number os elements in each sample
res <- data.frame(p=rep(NA,Nsim),R=rep(NA,Nsim),Sig=rep(NA,Nsim)) # pre-allocating space for the dataframe
for (i in c(1:Nsim)){
  # drawing 10 elements for each random variable (x and y) with a covariance matrix equal to Sigma
  D <- mvrnorm(n = PopSize, rep(0, 2), Sigma, empirical = FALSE) 
  R<-rcorr(D[,1],D[,2]) # correlation between the x and y variables
  res[i,"R"] <- R$r[1,2] # storing the correlation value for further use
  res[i,"p"]<-R$P[1,2]# storing the p-value for further use
  res[i,"Sig"]<-res[i,"p"]<0.05 # tag p-values smaller than the type II error threshold (here 0.05)
}
```

In the code above the R-dataframe `res` stores the results of the correlation between x (first colunm of D - `D[,1]`) and y (second column of D = `D[,2]`). The value of the correlation coefficient (`R$r[1,2]`) and the associated p-value (`R$p[1,2]`) are stored in this dataframe.

In the absence of correlation, one should expect a uniform distribution of the p-values from 0 to 1. This is what is obseved in the graph below:
``` {r eval=FALSE}
# plotting the distribution of p-values
Fcolor <- c("orange","lightblue")
ggplot(res, aes(x=p, fill=Sig)) + 
  geom_histogram(aes(x=p,fill=Sig),binwidth=.05,boundary = 0.05,color="black")+
  scale_fill_manual(values = Fcolor)
```

```{r, echo=FALSE} 
PP2
```

Interestingly, even in the absence of correlation between x and y, there is a subset of correlations associated with a p-value under the type II error threshold. Those are highlighted in orange in the figure above and are called false-positives. That is, these correlations are significant despite the fact that the variables x and y (from which only a few sample was taken) are not correlated by design. Given that the distribution of p-values is uniform and p-values fall in the interval [0,1], there will always be 5% of the p-values under the threshold of 0.05, independently of the number of samples for the two variables (one can test that by increasing the value of PopSize in the code above and re-running the code).

### understanding the influence of sample size (and power) on the magnitude of the false-positive correlations

``` {r, echo=FALSE}
  Rsig <- mean(res$R[res$Sig==0])
  Rall <- mean(res$R)
  if (Rsig>Rval){Rpos <- c("left","right")}else{Rpos <- c("right","left")}
PP1 <- ggplot(res, aes(x=R, fill=Sig)) + 
    geom_histogram(aes(x=R,fill=Sig),binwidth=.05,boundary = 0,color="black") +
    scale_fill_manual(values = Fcolor) +
    coord_cartesian(xlim = c(-1, 1))+
    geom_vline(xintercept=Rsig, linetype="dashed", color = "darkorange", size = 1) +
    geom_label(aes(x = Rsig, y = Inf, label = "Sig."), 
               hjust = Rpos[1], 
               vjust = "top", 
               colour = "darkorange", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    geom_vline(xintercept=Rval, linetype="dashed", color = "darkblue", size = 1) +
    geom_label(aes(x = Rval, y=Inf, label = "Actual"),
               hjust = Rpos[2], 
               vjust = "top", 
               colour = "darkblue", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    theme(legend.position='none') +
    scale_y_continuous(expand = c(0.15,0)) +
    labs(title="",x="correlation coefficient" , y="Count")
```
The distribution of the correlation coefficient will allow us to understand the problem with small sample size and why significant results always look convincing with small sample size.
To plot the distribution of simulated correlation coefficient, one can use the `res` dataframe:
```{r, eval=FALSE} 
ggplot(res, aes(x=R, fill=Sig)) + 
    geom_histogram(aes(x=R,fill=Sig),binwidth=.05,boundary = 0,color="black") +
    scale_fill_manual(values = Fcolor)
```

The false-positive correlations are associated with rather large correlations (absolute value > 0.6). 

```{r, echo=FALSE} 
PP1
```

That is, when using small sample size (here 10 observations for each variable), false-positive correlations have a high value and appear therefore very convincing. "Such a large correlation can only be true" would say an inexperienced scientist. Such high false-positive correlation is often accepted as solid proof but his part of the significance fallacy.

``` {r echo=FALSE}
PopSize75 = 75 #number os elements in each sample
res75 <- data.frame(p=rep(NA,Nsim),R=rep(NA,Nsim),Sig=rep(NA,Nsim)) # pre-allocating space for the dataframe
for (i in c(1:Nsim)){
  # drawing 75 elements for each random variable (x and y) with a covariance matrix equal to Sigma
  D <- mvrnorm(n = PopSize75, rep(0, 2), Sigma, empirical = FALSE) 
  R<-rcorr(D[,1],D[,2]) # correlation between the x and y variables
  res75[i,"R"] <- R$r[1,2] # storing the correlation value for further use
  res75[i,"p"]<-R$P[1,2]# storing the p-value for further use
  res75[i,"Sig"]<-res75[i,"p"]<0.05 # tag p-values smaller than the type II error threshold (here 0.05)
}
CountSig75 <- sum(res75$Sig)
Psig75 <- CountSig75/length(res75$Sig)
res75$Sig = factor(1-res75$Sig)
Rsig <- mean(res75$R[res75$Sig==0])
Rall <- mean(res75$R)
if (Rsig>Rall){Rpos <- c("left","right")}else{Rpos <- c("right","left")}
PP175 <- ggplot(res75, aes(x=R, fill=Sig)) + 
  geom_histogram(aes(x=R,fill=Sig),binwidth=.05,boundary = 0,color="black") +
  scale_fill_manual(values = Fcolor) +
  coord_cartesian(xlim = c(-1, 1))+
  geom_vline(xintercept=Rsig, linetype="dashed", color = "darkorange", size = 1) +
  geom_label(aes(x = Rsig, y = Inf, label = "Sig."), 
             hjust = Rpos[1], 
             vjust = "top", 
             colour = "darkorange", 
             label.size = NA, 
             size = 3,
             fill = NA)+
  geom_vline(xintercept=Rval, linetype="dashed", color = "darkblue", size = 1) +
  geom_label(aes(x = Rval, y=Inf, label = "Actual"),
             hjust = Rpos[2], 
             vjust = "top", 
             colour = "darkblue", 
             label.size = NA, 
             size = 3,
             fill = NA)+
  theme(legend.position='none') +
  scale_y_continuous(expand = c(0.15,0)) +
  labs(title="",x="correlation coefficient" , y="Count")

PP175
```

Increasing the sample size has a direct influence on the magnitude of these false-positive correlations. One can build a new `res` dataframe with the sample size of `r PopSize75` (`PopSize =` `r PopSize75`).

The significance fallacy has important consequences for the publishability of findings. If two researchers are (unknowingly) reporting a false-positive correlation with N=`r PopSize` and R=0.7 for researcher A and with N=`r PopSize75` and R=0.4 for researcher B, which one will more easily publish in a high-impact journal (whatever that means...)?

### understanding the multiple comparison problem.

these simulations also show that if we keep simulating random variables, we are assured of getting at least one significant correlation. With `r Nsim` simulations, there is 100% chance that at least one correlation will be significant. This exemplifies that if someone keeps trying to test correlation between many possible variables, the probability of getting a significant correlation even if there should be no correlation.

```{r, echo=FALSE}
Rval50 = 0.5
```

## simulating a single correlation R=`r Rval50`

To simulate two variables with a given correlation, one can also use the `mvnorm` function but this time with a covariance matrix exhibiting the value for the simulated correlation on the off-diagonal elements. For instance, if we want to simulate two variables with a correlation of R=`r Rval50`, then the covariance matrix is:
$$
Sigma = \begin{pmatrix}
1 & `r Rval50`\\
`r Rval50` & 1
\end{pmatrix}
$$
```{r, echo=FALSE}
set.seed(12)# to make sure everybody gets the same results
Sigma <- matrix(c(1,Rval50,Rval50,1),2,2)
D <- mvrnorm(n = PopSize, rep(0, 2), Sigma, empirical = FALSE) 
  R<-rcorr(D[,1],D[,2]) # correlation between the x and y variables
Scatter2 <- data.frame(x=D[,1],y=D[,2])
PP4 <- ggplot(Scatter2, aes(x=x, y=y)) +
  geom_point()+
  geom_smooth(method='lm',formula=y~x)+
  labs(title = "",x="Random variable 1", y="Random variable 2")

PP4
```
Together, these two variables are correlated with a correlation coefficient R= `r format(R$r[1,2], digits = 3)` (p-value = `r format(R$P[1,2], digits=3)`). Off course, the correlation between these two variables is not exactly zero. We will see later how we can recover the actual simulated correlation. 

## What is the expected p-value distribution if there is a correlation

Now, we will repeat this process a number of times in order to obtain the distribution of the p-values when there is a correlation R=`r Rval50`. 
When there is an underlying correlation between the two variables, the distribution of p-values becomes asymmetric with more p-values under 0.05.
``` {r, echo=FALSE}
set.seed(123)# to make sure everybody gets the same results
res <- data.frame(p=rep(NA,Nsim),R=rep(NA,Nsim),Sig=rep(NA,Nsim))
Sigma <- matrix(c(1,Rval50,Rval50,1),2,2)
for (i in c(1:Nsim)){
      D <- mvrnorm(n = PopSize, rep(0, 2), Sigma, empirical = FALSE)
      R<-rcorr(D[,1],D[,2])
      res[i,"R"] <- R$r[1,2]
      res[i,"p"]<-R$P[1,2]
      res[i,"Sig"]<-res[i,"p"]<0.05
}

Fcolor <- c("orange","lightblue")
CountSig <- sum(res$Sig)
Psig <- CountSig/length(res$Sig)
res$Sig = factor(1-res$Sig)
PP2 <- ggplot(res, aes(x=p, fill=Sig)) + 
    geom_histogram(aes(x=p,fill=Sig),binwidth=.05,boundary = 0.05,color="black") +
    scale_fill_manual(values = Fcolor) +
    geom_hline(yintercept=CountSig, linetype="dashed", color = "black") +
    geom_label(aes(x = 0, y = CountSig, label = "H0"), 
               hjust = "left", 
               vjust = "bottom", 
               colour = "black", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    coord_cartesian(xlim = c(0, 1))+
    theme(legend.position='none')+
    scale_y_continuous(expand = c(0.1,0)) +
    labs(title="",x="p-value" , y="Count")

PP2

d=data.frame(x1=c(0.33,0.33), x2=c(0.66,0.66), y1=c(0,Psig), y2=c(Psig,1), t=c('a','b'))
  PP3 <- ggplot() +  
    geom_rect(data=d, mapping=aes(xmin=x1, xmax=x2, ymin=y1, ymax=y2, fill=t), 
              color="black") +
    scale_fill_manual(values = Fcolor, 
                      name="",
                      labels=c("p<=0.05", "p>0.05")) +
    geom_hline(yintercept=0.05, linetype="dashed", color = "red") +
    geom_label(aes(x = 0.1, y = 0.05, label = "Type 1 \nError"), 
               hjust = "center", 
               vjust = "bottom", 
               colour = "red", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    geom_hline(yintercept=0.8, linetype="dashed", color = "black") +
    geom_label(aes(x = 0.1, y = 0.8, label = "Type 2 \nError"), 
               hjust = "center", 
               vjust = "center", 
               colour = "black", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    geom_hline(yintercept=0, color = "black") +
    coord_cartesian(xlim = c(0, 1),ylim = c(0, 1))+
    labs(title="",y="\n \n \nProportion of simulations")+
    scale_y_continuous(expand = c(0,0)) +
    theme(axis.text.x=element_blank(),
          axis.ticks.x=element_blank())
```

### understanding power

However, note that not all simulated correlations are significant. The percentage of significant correlations is equal the power of an experiment designed to detect a correlation of R=`r Rval` with `r PopSize` observations. Indeed, the power of an experiment can be defined as the chance that an experiment designed to detect a given effect (here a correlation) will actually do so (100%-power is also referred to as type II error or false negative). In our case, we performed as many experiments as we simulated correlations but only `r format(100*Psig, digits = 1)`% from them were significant. That means that if we have `r PopSize` observations from two populations that are correlated with R=`r Rval`, we have `r format(100*Psig, digits = 1)`% of detecting a significant correlation. This is illustrated on the graph below:

``` {r echo=FALSE}
PP3
PopSize28 = 28
set.seed(123)# to make sure everybody gets the same results
Nsim=1000
  res28 <- data.frame(p=rep(NA,Nsim),R=rep(NA,Nsim),Sig=rep(NA,Nsim))
Sigma <- matrix(c(1,Rval50,Rval50,1),2,2)
for (i in c(1:Nsim)){
      D <- mvrnorm(n = PopSize28, rep(0, 2), Sigma, empirical = FALSE)
      R<-rcorr(D[,1],D[,2])
      res28[i,"R"] <- R$r[1,2]
      res28[i,"p"]<-R$P[1,2]
      res28[i,"Sig"]<-res28[i,"p"]<0.05
}

Fcolor <- c("orange","lightblue")
CountSig28 <- sum(res28$Sig)
Psig28 <- CountSig28/length(res28$Sig)
res28$Sig = factor(1-res28$Sig)
d=data.frame(x1=c(0.33,0.33), x2=c(0.66,0.66), y1=c(0,Psig28), y2=c(Psig28,1), t=c('a','b'))
  PP28 <- ggplot() +  
    geom_rect(data=d, mapping=aes(xmin=x1, xmax=x2, ymin=y1, ymax=y2, fill=t), 
              color="black") +
    scale_fill_manual(values = Fcolor, 
                      name="",
                      labels=c("p<=0.05", "p>0.05")) +
    geom_hline(yintercept=0.05, linetype="dashed", color = "red") +
    geom_label(aes(x = 0.1, y = 0.05, label = "Type 1 \nError"), 
               hjust = "center", 
               vjust = "bottom", 
               colour = "red", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    geom_hline(yintercept=0.8, linetype="dashed", color = "black") +
    geom_label(aes(x = 0.1, y = 0.8, label = "Type 2 \nError"), 
               hjust = "center", 
               vjust = "center", 
               colour = "black", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    geom_hline(yintercept=0, color = "black") +
    coord_cartesian(xlim = c(0, 1),ylim = c(0, 1))+
    labs(title="",y="\n \n \nProportion of simulations")+
    scale_y_continuous(expand = c(0,0)) +
    theme(axis.text.x=element_blank(),
          axis.ticks.x=element_blank())
```

As indicated on this graph, the expected power of an experiment is 80% (or 90%). Yet, this is here not the case. To detect a correlation R=`r Rval`, one needs `r PopSize28` observations. In this case, the percentage of significant correlations reaches the power requirement of 80%.
``` {r echo=FALSE}
PP28
```

This manipulations demonstrate how one can get insights about the required sample size for detecting a correlation of a given value, do some simulations.
### effect of sample size on the accuracy of correlation estimation.

``` {r, echo=FALSE}
  Rsig <- mean(res$R[res$Sig==0])
  Rall <- mean(res$R)
  if (Rsig>Rval50){Rpos <- c("left","right")}else{Rpos <- c("right","left")}
PP150 <- ggplot(res, aes(x=R, fill=Sig)) + 
    geom_histogram(aes(x=R,fill=Sig),binwidth=.05,boundary = 0,color="black") +
    scale_fill_manual(values = Fcolor) +
    coord_cartesian(xlim = c(-1, 1))+
    geom_vline(xintercept=Rsig, linetype="dashed", color = "darkorange", size = 1) +
    geom_label(aes(x = Rsig, y = Inf, label = "Sig."), 
               hjust = Rpos[1], 
               vjust = "top", 
               colour = "darkorange", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    geom_vline(xintercept=Rval50, linetype="dashed", color = "darkblue", size = 1) +
    geom_label(aes(x = Rval50, y=Inf, label = "Actual"),
               hjust = Rpos[2], 
               vjust = "top", 
               colour = "darkblue", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    theme(legend.position='none') +
    scale_y_continuous(expand = c(0.15,0)) +
    labs(title="",x="correlation coefficient" , y="Count")
PP150
```

``` {r, echo=FALSE}
  Rsig28 <- mean(res28$R[res28$Sig==0])
  Rall28 <- mean(res28$R)
  if (Rsig28>Rall28){Rpos <- c("left","right")}else{Rpos <- c("right","left")}
PP150_28 <- ggplot(res28, aes(x=R, fill=Sig)) + 
    geom_histogram(aes(x=R,fill=Sig),binwidth=.05,boundary = 0,color="black") +
    scale_fill_manual(values = Fcolor) +
    coord_cartesian(xlim = c(-1, 1))+
    geom_vline(xintercept=Rsig28, linetype="dashed", color = "darkorange", size = 1) +
    geom_label(aes(x = Rsig28, y = Inf, label = "Sig."), 
               hjust = Rpos[1], 
               vjust = "top", 
               colour = "darkorange", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    geom_vline(xintercept=Rall28, linetype="dashed", color = "darkblue", size = 1) +
    geom_label(aes(x = Rall28, y=Inf, label = "Actual"),
               hjust = Rpos[2], 
               vjust = "top", 
               colour = "darkblue", 
               label.size = NA, 
               size = 3,
               fill = NA)+
    theme(legend.position='none') +
    scale_y_continuous(expand = c(0.15,0)) +
    labs(title="",x="correlation coefficient" , y="Count")
```

On the graph above, we can see that while many simulated correlations are around the value of `r Rval50`. However, the simulated correlations span a large range between `r format(min(res$R),digits = 2)` and  `r format(max(res$R),digits = 2)`. One can look at the effect of sample size on the precision of the estimated correlation. It is obvious that increasing the sample size (N= `r PopSize28`) decreases the range of simulated correlation ([`r format(min(res28$R),digits = 2)`,`r format(max(res28$R),digits = 2)`]). This has been described previously and illustrates that high power (here 80%) does not always correspond to high precision given the remaining variability of the simulated correlations.

``` {r echo=FALSE}
PP150_28
```

### understanding that publication bias inflates effect size

The graph above also indicates the importance of publishing non-significant findings. Indeed, if one looks at the average correlation for the significant correlations (orange dashed vertical line on the graphs above, with N= `r PopSize28`, average correlation is `r format(Rsig28,digits=3)`), this average correlation appears to overestimate the actual correlation value (R= `r Rval50`). In contrast, the average correlation over all samples (darkblue dashed vertical line on the graphs above) is much closer to the actual simulated correlation (with N= `r PopSize28`, average correlation is `r format(Rall28,digits=3)`). Furhermore, this overestimation of the actual correlation is even bigger with smaller sample sizes (with N= `r PopSize`, average correlation from significant studies is R=`r format(Rsig,digits=3)` while average correlation from all studies is R= `r format(Rall,digits=3)`)
If we look at the mean correlation from only significant studies, it is always larger than the actual population average correlation.

# Learning about sensitivity of correlations from simulated correlations.
The use of correlation is widespread in science. Yet, correlations are very sensitive to violations of the assumptions. Here, we will show that 1) in the absence of correlation (R=0), the presence of an outlier dramatically increases the false-positive rate (more than 5% of correlations are significant when R=0); 2) if data are pooled between two different groups (e.g. young adults vs. old adults) and the means for the two groups differ on the two variables.

## the outlier problem: simulation and solution

``` {r echo=FALSE}
set.seed(123)# to make sure everybody gets the same results
Sigma <- matrix(c(1,Rval,Rval,1),2,2)
SDdist <- 3
POP <- c("Main","outlier")
D <- mvrnorm(n = PopSize, rep(0, 2), Sigma, empirical = FALSE)
mMeans<-apply(D,2,mean)
mStd<-apply(D,2,sd)
D[PopSize,]<-mMeans+SDdist*mStd
Z <- c(rep(0,PopSize-1),1)
Scatter1 <- data.frame(D1=D[,1],D2=D[,2],Zf= factor(Z))
Rout<-rcorr(D[,1],D[,2])

cols <- c("royalblue3", "orangered2" )
Outlier4 <- ggplot(Scatter1) + 
  geom_point(aes(x=D1, y=D2, color=Zf))+
  geom_smooth(aes(x=D1, y=D2),method='lm',se=FALSE,formula = y~x)+
  scale_color_manual(name = "Population(s)", 
                     values = cols,
                     labels = POP)+
  labs(title = "",x="Random variable 1" , y="Random variable 2")
```

To generate an outlier, we will first generate the x and y parameteres for the 'r PopSize' individuals. We will then compute their mean and standard deviation, the data from the last individual will then be replaced by a point 'r SDdist' standard deviation away from the mean (mean + 3*SD). This will be done for both x and y variables for this individual. By doing so, one obtains the following grahics.

``` {r echo=FALSE}
Outlier4
```

In this case, we observe a strong correlation R=`r format(Rout$r[1,2], digits = 2)` (p=`r format(Rout$P[1,2], digits = 2)`). However, it is unclear whether more such correlations will turn out to be significant in the presence of an outlier. Therefore, as we did above, we will generate many such samples and test whether the presence of an outlier increases the chance of getting a significant correlation.

### Simulation: How sensisitive are correlations to one outlier?

## testing solutions

How do we know that the solution is good? If type I error rate is 5% and if average correlation is closed to simulated one.

### Solution: robust parametric correlation
### Solution: non-parametric correlation - Spearman

## How sensisitive are correlations to subgroups?

## Solution to the subgroup problem
### Spearmann is not a solution
### Taking subgroups into account


## extending this line of thought to the T-test
